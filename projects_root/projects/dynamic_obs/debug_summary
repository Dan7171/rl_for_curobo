##################  mpc_result = robots[i].solver.step(robots[i].current_state, max_attempts=2) ####################
In: projects_root/examples/mpc_moving_obstacles_mpc_mpc.py row 1382 
Job: Run rollouts(current policy), update policy, and return next action


################### NOW WE RUN ROLLOUTS AND OPTIMIZE *CURRENT* POLICY ########################


########## AFTER OPTIMIZATION DONE, WE NEED TO SHIFT THE POLICY ONE STEP FORWARD (TO START FROM NEXT TS) AND TAKE THE FIRST ACTION ##########
act = self.safety_rollout.get_robot_command(
                filtered_state, act_seq, shift_steps=shift_steps
            ) # JOB: TO SHIFT THE POLICY AND RETURN NEXT ACTION
            
# filtered_state is the current joints state. JOINTS POSITION, VELOCITY AND ACCELERATION
# act_seq is the new optimized policy before the shift ( HX7 MATRIX OF ACCELERATIONS) 
# shift_steps is 1 (num of steps to shift)
# returns "act":  the next action to execute  

################## Then, it calls to: #################### 
# self.dynamics_model.get_robot_command(
            current_state, 
            act_seq, 
            shift_steps=shift_steps, # 1
            state_idx=state_idx,
        ) 
In: curobo/src/curobo/rollout/arm_base.py row 685


################### Calls to: #######################
# cmd = the next action returned to the mpc to execute. 
# .integrate_action(act_step, current_state) takes the action selected after optimizing the policy (an acceleration vector) and the current state, and computes the velocity and position 
- 1. act_step which is the next step's acceleration vector (7). This is the first row of the current policy (corresponding to the first time step over H).
- 2. current_state is just current joint state (position, velocity, acceleration).
curobo/src/curobo/rollout/dynamics_model/kinematic_model.py row 545: cmd = self.state_filter.integrate_action(act_step, current_state)

self.cmd_joint_state.acceleration[:] = qdd_des # act_step. Means "by how much to increase velocity in the next command"
self.cmd_joint_state.velocity[:] = self.cmd_joint_state.velocity + qdd_des * dt # compute the velocity of the command (constant vel) based on the input acceleration.
self.cmd_joint_state.position[:] = (self.cmd_joint_state.position + self.cmd_joint_state.velocity * dt) # computes the input 

FULL CALL STACK:
integrate_acc (/home/dan/rl_for_curobo/curobo/src/curobo/util/state_filter.py:112)
get_robot_command (/home/dan/rl_for_curobo/curobo/src/curobo/rollout/dynamics_model/kinematic_model.py:545)
decorate_context (/home/dan/rl_for_curobo/isaac_sim-4.0.0/exts/omni.isaac.ml_archive/pip_prebundle/torch/utils/_contextlib.py:115)
get_robot_command (/home/dan/rl_for_curobo/curobo/src/curobo/rollout/arm_base.py:685)
solve (/home/dan/rl_for_curobo/curobo/src/curobo/wrap/wrap_mpc.py:63) # In: St, Pi(t:t+H) after optimization, before shifting (accelerations only). Out: Next action (acceleration, velocity and most importantly position) 
_solve_from_solve_state (/home/dan/rl_for_curobo/curobo/src/curobo/wrap/reacher/mpc.py:863)
_step_once (/home/dan/rl_for_curobo/curobo/src/curobo/wrap/reacher/mpc.py:784)
step (/home/dan/rl_for_curobo/curobo/src/curobo/wrap/reacher/mpc.py:542)
main (/home/dan/rl_for_curobo/projects_root/examples/mpc_moving_obstacles_mpc_mpc.py:1382)
<module> (/home/dan/rl_for_curobo/projects_root/examples/mpc_moving_obstacles_mpc_mpc.py:1585)
